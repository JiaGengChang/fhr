{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of 10 shuffles of 5-fold splits \n",
    "\n",
    "Identify complete samples, which have all input data types and risk labels\n",
    "\n",
    "Divide complete samples equally into 5 portions (137 or 138 samples)\n",
    "\n",
    "Stratified by risk label \n",
    "\n",
    "Assign remaining samples to trainign data\n",
    "\n",
    "Example output: \n",
    "\n",
    "`data/splits/1/train_1.txt`\n",
    "\n",
    "`data/splits/8/test_5.txt`\n",
    "\n",
    "Data types considered:\n",
    "\n",
    "FHR, gene exp, broad cn, mutations (**no gene fusion**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv('/home/jiageng/Documents/fhr/annotations/fhr-annotations.2Mar25.tsv',sep='\\t')[['PUBLIC_ID','risk']]\n",
    "public_ids_labels = labels.loc[labels['risk']!=-1]['PUBLIC_ID']\n",
    "print(len(public_ids_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806\n"
     ]
    }
   ],
   "source": [
    "public_ids_gene_exp = pd.read_csv('/home/jiageng/Documents/fhr/matrices/gene_exp_matrix_k20.tsv',sep='\\t')['PUBLIC_ID']\n",
    "print(len(public_ids_gene_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "924\n"
     ]
    }
   ],
   "source": [
    "public_ids_broad_cn = pd.read_csv('/home/jiageng/Documents/fhr/matrices/broad_cn_matrix.tsv',sep='\\t')['PUBLIC_ID']\n",
    "print(len(public_ids_broad_cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974\n"
     ]
    }
   ],
   "source": [
    "public_ids_mut = pd.read_csv('/home/jiageng/Documents/fhr/matrices/gene_mut_matrix_fdr.tsv',sep='\\t')['PUBLIC_ID']\n",
    "print(len(public_ids_mut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906\n"
     ]
    }
   ],
   "source": [
    "public_ids_canonical_ig = pd.read_csv('/home/jiageng/Documents/fhr/matrices/canonical_ig_translocations.tsv',sep='\\t').index.tolist()\n",
    "print(len(public_ids_canonical_ig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798\n"
     ]
    }
   ],
   "source": [
    "public_ids_gene_fusion = pd.read_csv('/home/jiageng/Documents/fhr/matrices/gene_fusion_matrix.tsv',sep='\\t')['PUBLIC_ID']\n",
    "print(len(public_ids_gene_fusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "924\n"
     ]
    }
   ],
   "source": [
    "public_ids_cn_segment = pd.read_csv('/home/jiageng/Documents/fhr/matrices/segment_cn_matrix_uncorrelated.tsv',sep='\\t').index.tolist()\n",
    "print(len(public_ids_cn_segment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1170\n"
     ]
    }
   ],
   "source": [
    "public_ids_all = \\\n",
    "    set(labels.PUBLIC_ID).union(\n",
    "        set(public_ids_gene_exp),\n",
    "        set(public_ids_broad_cn),\n",
    "        set(public_ids_mut),\n",
    "        set(public_ids_canonical_ig),\n",
    "        set(public_ids_cn_segment),\n",
    "        # set(public_ids_gene_fusion) # 1170 with or without gene fusion\n",
    "    )\n",
    "print(len(public_ids_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668\n"
     ]
    }
   ],
   "source": [
    "public_ids_common = \\\n",
    "    set(public_ids_labels).intersection(\n",
    "    set(public_ids_gene_exp),\n",
    "    set(public_ids_broad_cn),\n",
    "    set(public_ids_mut),\n",
    "    set(public_ids_canonical_ig),\n",
    "    set(public_ids_cn_segment),\n",
    "    # set(public_ids_gene_fusion) # 668 without gene fusion, 664 with gene fusion\n",
    ")\n",
    "print(len(public_ids_common))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all = labels.set_index('PUBLIC_ID').reindex(public_ids_all).fillna(-1).astype(int).reset_index('PUBLIC_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1 - a dataset with complete and incomplete samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ann = labels_all.copy() # results\n",
    "labels_valid = labels_all.query('PUBLIC_ID in @public_ids_common').reset_index(drop=True) # temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 10, random_state=42)\n",
    "for i, (_, test_ind) in enumerate(splitter.split(labels_valid[['risk']],labels_valid['risk'])):\n",
    "    public_ids_valid = labels_valid.loc[test_ind,'PUBLIC_ID']\n",
    "    labels_ann[f'{i//5 + 1}_{i%5 + 1}'] = False \n",
    "    labels_ann.loc[labels_ann['PUBLIC_ID'].isin(public_ids_valid),f'{i//5 + 1}_{i%5 + 1}'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6_1    6_2    6_3    6_4    6_5  \n",
       "False  False  False  False  False    497\n",
       "                            True     134\n",
       "                     True   False    134\n",
       "              True   False  False    135\n",
       "       True   False  False  False    135\n",
       "True   False  False  False  False    135\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ann.groupby(['6_1','6_2','6_3','6_4','6_5']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write public ids to text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for shuffle in range(1,11):\n",
    "    for fold in range(1,6):\n",
    "        labels_ann.loc[labels_ann[f'{shuffle}_{fold}']]['PUBLIC_ID'].to_csv(f'../data/splits/{shuffle}/valid_{fold}.txt',index=False)\n",
    "        labels_ann.loc[~labels_ann[f'{shuffle}_{fold}']]['PUBLIC_ID'].to_csv(f'../data/splits/{shuffle}/train_{fold}.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1_1    risk\n",
       "False   0      451\n",
       "       -1      286\n",
       "        1      221\n",
       "        2       77\n",
       "True    0       77\n",
       "        1       42\n",
       "        2       16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ann.groupby(['1_1'])['risk'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7_4    risk\n",
       "False   0      452\n",
       "       -1      286\n",
       "        1      221\n",
       "        2       77\n",
       "True    0       76\n",
       "        1       42\n",
       "        2       16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ann.groupby(['7_4'])['risk'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2 - a dataset with only complete samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_valid = labels_all.query('PUBLIC_ID in @public_ids_common').reset_index(drop=True) # reference\n",
    "labels_ann = labels_valid.copy() # results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 10, random_state=42)\n",
    "for i, (_, test_ind) in enumerate(splitter.split(labels_valid[['risk']],labels_valid['risk'])):\n",
    "    public_ids_valid = labels_valid.loc[test_ind,'PUBLIC_ID']\n",
    "    labels_ann[f'{i//5 + 1}_{i%5 + 1}'] = False \n",
    "    labels_ann.loc[labels_ann['PUBLIC_ID'].isin(public_ids_valid),f'{i//5 + 1}_{i%5 + 1}'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6_1    6_2    6_3    6_4    6_5  \n",
       "False  False  False  False  True     133\n",
       "                     True   False    133\n",
       "              True   False  False    134\n",
       "       True   False  False  False    134\n",
       "True   False  False  False  False    134\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ann.groupby(['6_1','6_2','6_3','6_4','6_5']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write public ids to text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for shuffle in range(1,11):\n",
    "    for fold in range(1,6):\n",
    "        labels_ann.loc[labels_ann[f'{shuffle}_{fold}']]['PUBLIC_ID'].to_csv(f'../data/splits/{shuffle}/valid_{fold}.txt',index=False)\n",
    "        labels_ann.loc[~labels_ann[f'{shuffle}_{fold}']]['PUBLIC_ID'].to_csv(f'../data/splits/{shuffle}/train_{fold}.txt',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1_1    risk\n",
       "False  0       324\n",
       "       1       157\n",
       "       2        53\n",
       "True   0        81\n",
       "       1        40\n",
       "       2        13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ann.groupby(['1_1'])['risk'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2_4    risk\n",
       "False  0       324\n",
       "       1       158\n",
       "       2        53\n",
       "True   0        81\n",
       "       1        39\n",
       "       2        13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ann.groupby(['2_4'])['risk'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 3 - train/valid/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_full = labels_all.query('PUBLIC_ID in @public_ids_common').reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dev, labels_test = train_test_split(labels_full, test_size=150, random_state=42950342, stratify=labels_full['risk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test.to_csv('../data/splits/test.txt',index=False)\n",
    "labels_dev.to_csv('../data/splits/dev.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind, valid_ind = splitter.split(labels_dev['risk'],labels_dev[['risk']],).__iter__().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "risk\n",
       "0    251\n",
       "1    122\n",
       "2     41\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dev.iloc[train_ind]['risk'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 10, random_state=42)\n",
    "\n",
    "for i, (train_ind, valid_ind) in enumerate(splitter.split(labels_dev[['risk']],labels_dev['risk'])):\n",
    "    train_labels = labels_dev.iloc[train_ind]\n",
    "    valid_labels = labels_dev.iloc[valid_ind]\n",
    "    shuffle = i//5 + 1\n",
    "    fold = i%5 + 1\n",
    "    os.makedirs(f'../data/splits/{shuffle}', exist_ok=True)\n",
    "    train_labels.to_csv(f'../data/splits/{shuffle}/train_{fold}.txt',index=False)\n",
    "    valid_labels.to_csv(f'../data/splits/{shuffle}/valid_{fold}.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
